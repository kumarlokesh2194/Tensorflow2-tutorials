{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we're monitoring the performance of our model on the validation set, we're still having to fix the number of epochs that the model is training for ahead of time. What we would like to do is to have the ability to not only monitor the performance of the network, but also perform certain actions depending on those performance measures. That's where callbacks come in. Callbacks are an important type of object TensorFlow and Keras that are designed to be able to monitor the loss in metrics at certain points in the training run and perform some action that might depend on those loss in metric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingCallback(Callback):\n",
    "    def on_train_begin(self, logs = None):\n",
    "        print(\"Starting training\")\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        print(f\"Starting epoch {epoch}\")\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs = None):\n",
    "        print(f\"Training : starting batch {batch}\")\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs = None):\n",
    "        print(f\"Training: finished batch {batch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        print(f\"Finished epoch {epoch}\")\n",
    "        \n",
    "    def on_train_end(self, logs = None):\n",
    "        print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the testing callbacks\n",
    "\n",
    "class TestingCallback(Callback):\n",
    "    def on_test_begin(self, logs = None):\n",
    "        print(\"Starting testing\")\n",
    "        \n",
    "        \n",
    "    def on_test_batch_begin(self, batch, logs = None):\n",
    "        print(f\"Testing : starting batch {batch}\")\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs = None):\n",
    "        print(f\"Testing: finished batch {batch}\")\n",
    "        \n",
    "    def on_test_end(self, logs = None):\n",
    "        print(\"finished testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting callback\n",
    "\n",
    "class PredictCallback(Callback):\n",
    "    def on_predict_begin(self, logs = None):\n",
    "        print(\"Starting predicting\")\n",
    "        \n",
    "        \n",
    "    def on_predict_batch_begin(self, batch, logs = None):\n",
    "        print(f\"predicting : starting batch {batch}\")\n",
    "        \n",
    "    def on_predict_batch_end(self, batch, logs = None):\n",
    "        print(f\"predicting: finished batch {batch}\")\n",
    "        \n",
    "    def on_predict_end(self, logs = None):\n",
    "        print(\"finished predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes_dataset = load_diabetes()\n",
    "print(diabetes_dataset[\"DESCR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])\n"
     ]
    }
   ],
   "source": [
    "# Save the input and target variables\n",
    "print(diabetes_dataset.keys())\n",
    "data = diabetes_dataset[\"data\"]\n",
    "targets = diabetes_dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47194752e-02, -1.00165882e+00, -1.44579915e-01,  6.99512942e-01,\n",
       "       -2.22496178e-01, -7.15965848e-01, -1.83538046e-01, -1.15749134e+00,\n",
       "       -5.47147277e-01,  2.05006151e+00, -6.64021672e-01, -1.07957508e+00,\n",
       "        3.48889755e-01,  4.26806019e-01, -4.43258925e-01,  2.45001404e-01,\n",
       "        1.80071184e-01, -1.05621783e-01, -7.15965848e-01,  2.06043272e-01,\n",
       "       -1.09256112e+00, -1.33929596e+00, -1.09256112e+00,  1.20596866e+00,\n",
       "        4.13819975e-01,  6.47568766e-01, -1.96524090e-01, -8.71798376e-01,\n",
       "       -2.74440354e-01,  1.69943833e+00, -3.00412442e-01, -1.20943552e+00,\n",
       "        2.45262887e+00, -8.45826288e-01, -1.13151925e+00, -6.51035629e-01,\n",
       "        1.46568953e+00,  1.60853602e+00,  1.29687096e+00, -8.06868156e-01,\n",
       "       -6.77007716e-01, -1.26137969e+00, -1.18346343e+00, -7.80896068e-01,\n",
       "        1.38777327e+00, -1.28735178e+00,  4.91736239e-01, -1.31593871e-01,\n",
       "       -1.00165882e+00, -1.31593871e-01,  3.72247006e-02,  9.46247777e-01,\n",
       "       -1.20943552e+00, -6.25063541e-01,  3.87847887e-01, -3.13398486e-01,\n",
       "       -1.30033783e+00, -1.49512849e+00,  2.32015360e-01,  2.32015360e-01,\n",
       "       -1.18346343e+00, -1.05621783e-01, -1.30033783e+00, -3.13398486e-01,\n",
       "       -1.05360299e+00,  1.41113052e-01, -2.77055191e-02, -7.15965848e-01,\n",
       "        1.02154920e-01,  3.35903711e-01, -1.35228200e+00,  1.53061975e+00,\n",
       "        6.47568766e-01, -5.34161233e-01, -8.71798376e-01, -1.43019827e+00,\n",
       "        2.32015360e-01,  6.21596678e-01,  1.29687096e+00, -5.08189145e-01,\n",
       "       -1.18607827e-01, -1.31332387e+00, -1.30033783e+00,  7.51457118e-01,\n",
       "       -1.13151925e+00, -1.44579915e-01, -1.26137969e+00, -2.35482222e-01,\n",
       "       -1.43019827e+00, -5.34161233e-01, -7.02979804e-01,  1.54099096e-01,\n",
       "       -1.35228200e+00, -7.28951892e-01, -8.06868156e-01,  1.28127008e-01,\n",
       "       -2.77055191e-02,  1.64749415e+00, -7.80896068e-01, -8.97770464e-01,\n",
       "       -3.13398486e-01, -6.51035629e-01,  1.94617316e+00,  5.95624590e-01,\n",
       "       -7.41937936e-01, -1.28735178e+00, -2.35482222e-01, -1.05621783e-01,\n",
       "        1.03715008e+00, -9.23742551e-01, -6.25063541e-01, -1.20943552e+00,\n",
       "        1.21895470e+00,  1.88124294e+00,  1.37478723e+00,  9.98191953e-01,\n",
       "        1.59554997e+00,  1.67346624e+00,  3.48889755e-01,  6.21596678e-01,\n",
       "        6.21596678e-01,  2.70973492e-01,  3.61875799e-01, -8.84784420e-01,\n",
       "       -4.04300794e-01,  1.15140964e-01, -6.89993760e-01, -5.60133321e-01,\n",
       "       -4.82217057e-01,  1.50464767e+00,  1.58256393e+00,  7.61828325e-02,\n",
       "       -5.86105409e-01, -8.97770464e-01, -6.38049585e-01,  1.55659184e+00,\n",
       "       -8.71798376e-01,  1.66048019e+00,  2.38769865e+00,  1.67346624e+00,\n",
       "       -4.43258925e-01,  2.14096382e+00,  1.07610822e+00, -1.19644947e+00,\n",
       "        2.83959536e-01,  1.38777327e+00,  3.35903711e-01, -3.13398486e-01,\n",
       "       -7.28951892e-01, -3.39370574e-01,  1.76436855e+00, -8.32840244e-01,\n",
       "        1.81631272e+00, -1.05360299e+00,  5.82638546e-01,  4.39792063e-01,\n",
       "       -1.65096101e+00, -8.84784420e-01, -7.28951892e-01,  5.56666458e-01,\n",
       "       -1.28735178e+00,  8.42359425e-01,  2.57987448e-01, -2.74440354e-01,\n",
       "        8.03401293e-01, -1.20943552e+00, -1.06658903e+00,  8.81317557e-01,\n",
       "        1.50464767e+00, -1.73343121e-03, -1.36526805e+00, -1.01464486e+00,\n",
       "        1.85527085e+00, -6.64021672e-01, -1.47194752e-02, -3.26384530e-01,\n",
       "        1.10208030e+00,  9.46247777e-01, -9.23742551e-01, -1.47194752e-02,\n",
       "       -5.86105409e-01, -1.14450530e+00, -1.83538046e-01,  4.26806019e-01,\n",
       "        1.46568953e+00, -6.64021672e-01, -1.96524090e-01, -1.18607827e-01,\n",
       "       -1.44579915e-01, -9.49714639e-01,  1.81631272e+00,  3.35903711e-01,\n",
       "       -7.93882112e-01, -4.69231013e-01, -8.58812332e-01, -3.91314750e-01,\n",
       "       -1.04061695e+00, -3.00412442e-01, -1.31593871e-01, -8.06868156e-01,\n",
       "        7.61828325e-02, -1.46915640e+00,  5.69652502e-01,  9.07289645e-01,\n",
       "        1.62152206e+00, -6.89993760e-01,  5.69652502e-01,  6.47568766e-01,\n",
       "        3.72247006e-02, -9.75686727e-01,  5.04722283e-01, -1.06658903e+00,\n",
       "       -1.02763090e+00, -1.33929596e+00, -1.13151925e+00,  1.43971745e+00,\n",
       "        1.24492679e+00,  1.86825690e+00,  8.03401293e-01,  4.26806019e-01,\n",
       "       -9.62700683e-01, -7.67910024e-01,  1.29687096e+00, -2.77055191e-02,\n",
       "       -9.75686727e-01,  7.25485030e-01, -9.75686727e-01, -5.73119365e-01,\n",
       "        1.02154920e-01, -1.28735178e+00,  8.81317557e-01,  2.42386567e-02,\n",
       "        1.38777327e+00, -8.06868156e-01,  1.21895470e+00, -3.65342662e-01,\n",
       "       -1.10554717e+00, -1.04061695e+00,  1.36180118e+00,  1.42673140e+00,\n",
       "        1.59554997e+00,  3.22917667e-01, -1.05360299e+00, -1.36526805e+00,\n",
       "        4.52778107e-01, -3.52356618e-01, -9.62700683e-01, -1.31332387e+00,\n",
       "        1.37478723e+00,  8.16387337e-01,  1.95915920e+00,  1.17999657e+00,\n",
       "       -7.93882112e-01, -2.77055191e-02,  2.05006151e+00,  1.12526127e-02,\n",
       "        2.51755909e+00, -1.15749134e+00, -8.19854200e-01, -1.32630991e+00,\n",
       "       -1.46915640e+00, -6.38049585e-01,  2.02408942e+00, -4.69231013e-01,\n",
       "       -9.26357388e-02, -1.01464486e+00, -1.39124013e+00, -4.82217057e-01,\n",
       "        1.45270349e+00, -8.45826288e-01,  6.47568766e-01, -3.26384530e-01,\n",
       "        3.87847887e-01,  1.15402448e+00, -1.11853321e+00, -7.54923980e-01,\n",
       "        1.69943833e+00, -1.14450530e+00, -6.51035629e-01,  6.21596678e-01,\n",
       "        1.46568953e+00, -7.54923980e-01,  1.01117800e+00,  3.74861843e-01,\n",
       "        5.02107446e-02,  1.05013613e+00, -1.19644947e+00,  8.68331513e-01,\n",
       "       -9.36728595e-01, -1.09256112e+00,  2.33575448e+00,  1.24492679e+00,\n",
       "       -8.84784420e-01,  6.21596678e-01, -1.26137969e+00, -8.71798376e-01,\n",
       "       -8.19854200e-01, -1.57304475e+00, -3.00412442e-01, -8.97770464e-01,\n",
       "        1.59554997e+00, -1.13151925e+00,  5.95624590e-01,  1.08909426e+00,\n",
       "        1.30985701e+00, -3.65342662e-01, -1.40422618e+00,  2.57987448e-01,\n",
       "       -4.95203101e-01, -1.31593871e-01, -5.60133321e-01,  3.61875799e-01,\n",
       "       -1.05621783e-01,  1.41113052e-01, -6.66636509e-02, -7.15965848e-01,\n",
       "        8.81317557e-01,  4.91736239e-01, -5.60133321e-01,  5.04722283e-01,\n",
       "       -3.91314750e-01,  1.01117800e+00,  1.16701052e+00,  1.24492679e+00,\n",
       "        1.25791283e+00,  5.17708327e-01, -2.74440354e-01,  1.10208030e+00,\n",
       "       -9.62700683e-01, -2.22496178e-01,  1.19298261e+00,  6.08610634e-01,\n",
       "        1.53061975e+00,  1.54099096e-01, -1.04061695e+00, -7.28951892e-01,\n",
       "        1.99811734e+00, -7.93882112e-01,  8.03401293e-01, -7.41937936e-01,\n",
       "        8.29373381e-01,  1.43971745e+00,  3.35903711e-01, -5.08189145e-01,\n",
       "        6.21596678e-01, -1.70552003e-01, -1.70552003e-01, -8.32840244e-01,\n",
       "       -5.36776070e-02, -8.32840244e-01,  1.17999657e+00, -1.05360299e+00,\n",
       "       -9.75686727e-01, -5.60133321e-01,  1.55659184e+00, -1.19644947e+00,\n",
       "       -1.27436574e+00,  8.94303601e-01, -8.06868156e-01,  2.06304756e+00,\n",
       "        1.67346624e+00,  3.87847887e-01,  2.19290800e+00, -1.22242156e+00,\n",
       "        1.42673140e+00,  6.99512942e-01,  1.05013613e+00,  1.16701052e+00,\n",
       "       -3.78328706e-01,  1.93057228e-01, -1.15749134e+00,  5.82638546e-01,\n",
       "       -1.05360299e+00,  2.06043272e-01, -1.57565959e-01,  8.42359425e-01,\n",
       "       -4.04300794e-01,  1.07610822e+00,  1.20596866e+00, -1.45617035e+00,\n",
       "       -1.30033783e+00, -6.25063541e-01, -2.61454310e-01, -8.32840244e-01,\n",
       "       -1.07957508e+00,  8.68331513e-01, -1.04061695e+00,  6.34582722e-01,\n",
       "       -5.47147277e-01, -1.31332387e+00,  1.62152206e+00, -1.15749134e+00,\n",
       "       -4.43258925e-01, -1.07957508e+00,  1.56957789e+00,  1.37478723e+00,\n",
       "       -1.41721222e+00,  5.95624590e-01,  1.16701052e+00,  1.03715008e+00,\n",
       "        2.96945580e-01, -7.67910024e-01,  2.06043272e-01,  1.59554997e+00,\n",
       "        1.82929877e+00,  1.67346624e+00, -1.04061695e+00, -1.57565959e-01,\n",
       "        4.78750195e-01,  3.74861843e-01,  7.38471074e-01, -2.09510134e-01,\n",
       "        1.41374536e+00, -5.08189145e-01, -2.74440354e-01,  2.83959536e-01,\n",
       "        1.36180118e+00, -1.26137969e+00, -8.84784420e-01, -1.43019827e+00,\n",
       "       -7.96496949e-02,  7.77429206e-01,  1.05013613e+00, -7.93882112e-01,\n",
       "       -5.34161233e-01, -1.73343121e-03, -4.17286837e-01, -1.10554717e+00,\n",
       "        2.05006151e+00, -7.54923980e-01,  4.00833931e-01, -1.11853321e+00,\n",
       "        2.70973492e-01, -1.04061695e+00, -1.33929596e+00, -1.14450530e+00,\n",
       "       -1.35228200e+00,  3.35903711e-01, -6.25063541e-01, -2.61454310e-01,\n",
       "        8.81317557e-01, -1.23540761e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the target data (this will make clearer training curves)\n",
    "\n",
    "targets = (targets-targets.mean(axis = 0))/targets.std()\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 10)\n",
      "(45, 10)\n",
      "(397,)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size = 0.1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the learning rate schedule. The tuples below are (start_epoch, new_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr_schedule = [\n",
    "    (0, 0.006), (20, 0.004), (45, 0.002), (70, 0.001)\n",
    "]\n",
    "\n",
    "def get_new_epoch_lr(epoch, lr):\n",
    "    # Checks to see if the input epoch is listed in the learning rate schedule \n",
    "    # and if so, returns index in lr_schedule\n",
    "    epoch_in_sched = [i for i in range(len(lr_schedule)) if lr_schedule[i][0]==int(epoch)]\n",
    "    if len(epoch_in_sched)>0:\n",
    "        # If it is, return the learning rate corresponding to the epoch\n",
    "        return lr_schedule[epoch_in_sched[0]][1]\n",
    "    else:\n",
    "        # Otherwise, return the existing learning rate\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom callback\n",
    "\n",
    "class LRScheduler(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, new_lr):\n",
    "        super(LRScheduler, self).__init__()\n",
    "        # Add the new learning rate function to our callback\n",
    "        self.new_lr = new_lr\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Make sure that the optimizer we have chosen has a learning rate, and raise an error if not\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "              raise ValueError('Error: Optimizer does not have a learning rate.')\n",
    "                \n",
    "        # Get the current learning rate\n",
    "        curr_rate = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "        \n",
    "        # Call the auxillary function to get the scheduled learning rate for the current epoch\n",
    "        scheduled_rate = self.new_lr(epoch, curr_rate)\n",
    "\n",
    "        # Set the learning rate to the scheduled learning rate\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_rate)\n",
    "        print('Learning rate for epoch {} is {:7.3f}'.format(epoch, scheduled_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0615 13:01:32.464303 139756527216448 deprecation.py:506] From /home/lokesh/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 84,097\n",
      "Trainable params: 84,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "# Build the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "\n",
    "def get_batchnormalized_model(wd, rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu', input_shape = (train_data.shape[1],)))\n",
    "    BatchNormalization()\n",
    "    Dropout(rate)\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu'))\n",
    "    BatchNormalization()\n",
    "    Dropout(rate)\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu'))\n",
    "    BatchNormalization()\n",
    "    Dropout(rate)\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu'))\n",
    "    BatchNormalization()\n",
    "    Dropout(rate)\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu'))\n",
    "    BatchNormalization()\n",
    "    Dropout(rate)\n",
    "    model.add(Dense(128, kernel_regularizer = regularizers.l2(wd), activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model2 = get_batchnormalized_model(0.001, 0.3)\n",
    "\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history2 = model2.fit(train_data, train_targets, epochs = 100,\n",
    "#                      validation_split = 0.25, batch_size = 64, verbose = 2, callbacks = [LRScheduler(get_new_epoch_lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 297 samples, validate on 100 samples\n",
      "Learning rate for epoch 0 is   0.006\n",
      "Epoch 1/100\n",
      "297/297 - 0s - loss: 1.7456 - val_loss: 1.4695\n",
      "Learning rate for epoch 1 is   0.006\n",
      "Epoch 2/100\n",
      "297/297 - 0s - loss: 1.2938 - val_loss: 1.3444\n",
      "Learning rate for epoch 2 is   0.006\n",
      "Epoch 3/100\n",
      "297/297 - 0s - loss: 1.1590 - val_loss: 1.2468\n",
      "Learning rate for epoch 3 is   0.006\n",
      "Epoch 4/100\n",
      "297/297 - 0s - loss: 1.0801 - val_loss: 1.1956\n",
      "Learning rate for epoch 4 is   0.006\n",
      "Epoch 5/100\n",
      "297/297 - 0s - loss: 1.0402 - val_loss: 1.1712\n",
      "Learning rate for epoch 5 is   0.006\n",
      "Epoch 6/100\n",
      "297/297 - 0s - loss: 1.0213 - val_loss: 1.1591\n",
      "Learning rate for epoch 6 is   0.006\n",
      "Epoch 7/100\n",
      "297/297 - 0s - loss: 1.0112 - val_loss: 1.1498\n",
      "Learning rate for epoch 7 is   0.006\n",
      "Epoch 8/100\n",
      "297/297 - 0s - loss: 1.0033 - val_loss: 1.1359\n",
      "Learning rate for epoch 8 is   0.006\n",
      "Epoch 9/100\n",
      "297/297 - 0s - loss: 1.0041 - val_loss: 1.1290\n",
      "Learning rate for epoch 9 is   0.006\n",
      "Epoch 10/100\n",
      "297/297 - 0s - loss: 0.9972 - val_loss: 1.1403\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_data, train_targets, epochs = 100,\n",
    "                     validation_split = 0.25, batch_size = 64, verbose = 2, callbacks = [LRScheduler(get_new_epoch_lr),tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 1, mode = 'min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing\n",
      "Testing : starting batch 0\n",
      "Testing: finished batch 0\n",
      "Testing : starting batch 1\n",
      "Testing: finished batch 1\n",
      "finished testing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8489999744627211"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_data, test_targets, verbose = False, callbacks = [TestingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting\n",
      "predicting : starting batch 0\n",
      "predicting: finished batch 0\n",
      "predicting : starting batch 1\n",
      "predicting: finished batch 1\n",
      "finished predicting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00175124],\n",
       "       [0.00141069],\n",
       "       [0.00101504],\n",
       "       [0.00142652],\n",
       "       [0.00226361],\n",
       "       [0.00161079],\n",
       "       [0.00138497],\n",
       "       [0.00216535],\n",
       "       [0.00129563],\n",
       "       [0.00113243],\n",
       "       [0.00136808],\n",
       "       [0.00169307],\n",
       "       [0.00105694],\n",
       "       [0.00125104],\n",
       "       [0.00168246],\n",
       "       [0.00142175],\n",
       "       [0.00194368],\n",
       "       [0.00143149],\n",
       "       [0.00113773],\n",
       "       [0.00129515],\n",
       "       [0.00178188],\n",
       "       [0.00124606],\n",
       "       [0.00142351],\n",
       "       [0.00154951],\n",
       "       [0.00171372],\n",
       "       [0.00214124],\n",
       "       [0.00160161],\n",
       "       [0.00151488],\n",
       "       [0.00146654],\n",
       "       [0.00146106],\n",
       "       [0.00215644],\n",
       "       [0.00143322],\n",
       "       [0.00200105],\n",
       "       [0.00109518],\n",
       "       [0.00146356],\n",
       "       [0.0015837 ],\n",
       "       [0.00164139],\n",
       "       [0.0010972 ],\n",
       "       [0.00199693],\n",
       "       [0.00195739],\n",
       "       [0.00148374],\n",
       "       [0.00156751],\n",
       "       [0.00197238],\n",
       "       [0.00214368],\n",
       "       [0.00312721]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(test_data, verbose = False, callbacks = [PredictCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1af04b4128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curves\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.DataFrame(history2.history)\n",
    "epochs = np.arange(len(frame))\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "# Loss plot\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(epochs, frame['loss'], label=\"Train\")\n",
    "ax.plot(epochs, frame['val_loss'], label=\"Validation\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Loss vs Epochs\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more convieient way for adding learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_function(epoch, lr):\n",
    "#     if epoch % 2 == 0:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr + epoch/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# history = model.fit(train_data, train_targets, epochs=10,\n",
    "#                     callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, verbose=1)], verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
